{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#!/usr/bin/python\n\nimport sys\nimport pickle\nsys.path.append(\"../tools/\")\n\nfrom feature_format import featureFormat, targetFeatureSplit\nfrom tester import dump_classifier_and_data\nimport pandas as pd\nimport numpy as np\n",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\n### Task 1: Select what features you'll use.\n### features_list is a list of strings, each of which is a feature name.\n### The first feature must be \"poi\".\nfeatures_list = ['poi','salary','deferral_payments', 'total_payments',\n                'loan_advances', 'bonus', 'restricted_stock_deferred',\n                'deferred_income', 'total_stock_value', 'expenses',\n                'exercised_stock_options', 'other', 'long_term_incentive',\n                'restricted_stock', 'director_fees', 'shared_receipt_with_poi',\n                'to_messages','from_messages', 'from_poi_to_this_person',\n                'from_this_person_to_poi'] # First I try with all features available\n\n### Load the dictionary containing the dataset\nwith open(\"final_project_dataset2.pkl\", \"rb\") as data_file:\n    data_dict = pickle.load(data_file)\nprint(f'Data Lenght: {len(data_dict)}')\n### Task 2: Remove outliers\n### Task 3: Create new feature(s)\n### Store to my_dataset for easy export below.\ndata_dict.pop('TOTAL', 0)\nprint(f'Data length after removing outliers: {len(data_dict)}')\nkeys = data_dict.keys()\ndf = pd.DataFrame.from_dict(data_dict, orient='index', columns=features_list).replace('NaN', np.nan)\nprint(df.head())\nprint(df.info())\nprint(df.describe())\n",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Data Lenght: 146\nData length after removing outliers: 145\n                      poi    salary  deferral_payments  total_payments  \\\nALLEN PHILLIP K     False  201955.0          2869717.0       4484442.0   \nBADUM JAMES P       False       NaN           178980.0        182466.0   \nBANNANTINE JAMES M  False     477.0                NaN        916197.0   \nBAXTER JOHN C       False  267102.0          1295738.0       5634343.0   \nBAY FRANKLIN R      False  239671.0           260455.0        827696.0   \n\n                    loan_advances      bonus  restricted_stock_deferred  \\\nALLEN PHILLIP K               NaN  4175000.0                  -126027.0   \nBADUM JAMES P                 NaN        NaN                        NaN   \nBANNANTINE JAMES M            NaN        NaN                  -560222.0   \nBAXTER JOHN C                 NaN  1200000.0                        NaN   \nBAY FRANKLIN R                NaN   400000.0                   -82782.0   \n\n                    deferred_income  total_stock_value  expenses  \\\nALLEN PHILLIP K          -3081055.0          1729541.0   13868.0   \nBADUM JAMES P                   NaN           257817.0    3486.0   \nBANNANTINE JAMES M          -5104.0          5243487.0   56301.0   \nBAXTER JOHN C            -1386055.0         10623258.0   11200.0   \nBAY FRANKLIN R            -201641.0            63014.0  129142.0   \n\n                    exercised_stock_options      other  long_term_incentive  \\\nALLEN PHILLIP K                   1729541.0      152.0             304805.0   \nBADUM JAMES P                      257817.0        NaN                  NaN   \nBANNANTINE JAMES M                4046157.0   864523.0                  NaN   \nBAXTER JOHN C                     6680544.0  2660303.0            1586055.0   \nBAY FRANKLIN R                          NaN       69.0                  NaN   \n\n                    restricted_stock  director_fees  shared_receipt_with_poi  \\\nALLEN PHILLIP K             126027.0            NaN                   1407.0   \nBADUM JAMES P                    NaN            NaN                      NaN   \nBANNANTINE JAMES M         1757552.0            NaN                    465.0   \nBAXTER JOHN C              3942714.0            NaN                      NaN   \nBAY FRANKLIN R              145796.0            NaN                      NaN   \n\n                    to_messages  from_messages  from_poi_to_this_person  \\\nALLEN PHILLIP K          2902.0         2195.0                     47.0   \nBADUM JAMES P               NaN            NaN                      NaN   \nBANNANTINE JAMES M        566.0           29.0                     39.0   \nBAXTER JOHN C               NaN            NaN                      NaN   \nBAY FRANKLIN R              NaN            NaN                      NaN   \n\n                    from_this_person_to_poi  \nALLEN PHILLIP K                        65.0  \nBADUM JAMES P                           NaN  \nBANNANTINE JAMES M                      0.0  \nBAXTER JOHN C                           NaN  \nBAY FRANKLIN R                          NaN  \n<class 'pandas.core.frame.DataFrame'>\nIndex: 145 entries, ALLEN PHILLIP K to YEAP SOON\nData columns (total 20 columns):\npoi                          145 non-null bool\nsalary                       94 non-null float64\ndeferral_payments            38 non-null float64\ntotal_payments               124 non-null float64\nloan_advances                3 non-null float64\nbonus                        81 non-null float64\nrestricted_stock_deferred    17 non-null float64\ndeferred_income              48 non-null float64\ntotal_stock_value            125 non-null float64\nexpenses                     94 non-null float64\nexercised_stock_options      101 non-null float64\nother                        92 non-null float64\nlong_term_incentive          65 non-null float64\nrestricted_stock             109 non-null float64\ndirector_fees                16 non-null float64\nshared_receipt_with_poi      86 non-null float64\nto_messages                  86 non-null float64\nfrom_messages                86 non-null float64\nfrom_poi_to_this_person      86 non-null float64\nfrom_this_person_to_poi      86 non-null float64\ndtypes: bool(1), float64(19)\nmemory usage: 22.8+ KB\nNone\n             salary  deferral_payments  total_payments  loan_advances  \\\ncount  9.400000e+01       3.800000e+01    1.240000e+02   3.000000e+00   \nmean   2.840875e+05       8.416025e+05    2.623421e+06   2.797500e+07   \nstd    1.771311e+05       1.289323e+06    9.488106e+06   4.638256e+07   \nmin    4.770000e+02      -1.025000e+05    1.480000e+02   4.000000e+05   \n25%    2.118020e+05       7.964450e+04    3.863802e+05   1.200000e+06   \n50%    2.587410e+05       2.210635e+05    1.100246e+06   2.000000e+06   \n75%    3.086065e+05       8.672112e+05    2.084663e+06   4.176250e+07   \nmax    1.111258e+06       6.426990e+06    1.035598e+08   8.152500e+07   \n\n              bonus  restricted_stock_deferred  deferred_income  \\\ncount  8.100000e+01               1.700000e+01     4.800000e+01   \nmean   1.201773e+06               6.218928e+05    -5.810498e+05   \nstd    1.441679e+06               3.845528e+06     9.420764e+05   \nmin    7.000000e+04              -1.787380e+06    -3.504386e+06   \n25%    4.250000e+05              -3.298250e+05    -6.112092e+05   \n50%    7.500000e+05              -1.402640e+05    -1.519270e+05   \n75%    1.200000e+06              -7.241900e+04    -3.792600e+04   \nmax    8.000000e+06               1.545629e+07    -8.330000e+02   \n\n       total_stock_value       expenses  exercised_stock_options  \\\ncount       1.250000e+02      94.000000             1.010000e+02   \nmean        3.352073e+06   54192.010638             2.959559e+06   \nstd         6.532883e+06   46108.377454             5.499450e+06   \nmin        -4.409300e+04     148.000000             3.285000e+03   \n25%         4.941360e+05   22479.000000             5.067650e+05   \n50%         1.095040e+06   46547.500000             1.297049e+06   \n75%         2.606763e+06   78408.500000             2.542813e+06   \nmax         4.911008e+07  228763.000000             3.434838e+07   \n\n              other  long_term_incentive  restricted_stock  director_fees  \\\ncount  9.200000e+01         6.500000e+01      1.090000e+02      16.000000   \nmean   4.652767e+05         7.464912e+05      1.147424e+06   89822.875000   \nstd    1.389719e+06         8.629174e+05      2.249770e+06   41112.700735   \nmin    2.000000e+00         6.922300e+04     -2.604490e+06    3285.000000   \n25%    1.209000e+03         2.750000e+05      2.520550e+05   83674.500000   \n50%    5.198450e+04         4.221580e+05      4.410960e+05  106164.500000   \n75%    3.575772e+05         8.318090e+05      9.850320e+05  112815.000000   \nmax    1.035973e+07         5.145434e+06      1.476169e+07  137864.000000   \n\n       shared_receipt_with_poi   to_messages  from_messages  \\\ncount                86.000000     86.000000      86.000000   \nmean               1176.465116   2073.860465     608.790698   \nstd                1178.317641   2582.700981    1841.033949   \nmin                   2.000000     57.000000      12.000000   \n25%                 249.750000    541.250000      22.750000   \n50%                 740.500000   1211.000000      41.000000   \n75%                1888.250000   2634.750000     145.500000   \nmax                5521.000000  15149.000000   14368.000000   \n\n       from_poi_to_this_person  from_this_person_to_poi  \ncount                86.000000                86.000000  \nmean                 64.895349                41.232558  \nstd                  86.979244               100.073111  \nmin                   0.000000                 0.000000  \n25%                  10.000000                 1.000000  \n50%                  35.000000                 8.000000  \n75%                  72.250000                24.750000  \nmax                 528.000000               609.000000  \n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\nimport seaborn as sns",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\n# after seeing my data and missing values now I will manually remove features\n# with lots of missing values\ncol_to_remove = [col for col in df.columns if df[col].isna().sum() >= 80]\nprint(f'No of columns to remove: {len(col_to_remove)}')\nprint(col_to_remove)\nprint(f'No of Features: {len(features_list)}')\nfeatures_list = [feature for feature in features_list if feature not in col_to_remove]\nprint(features_list)\nprint(f'No of Features after removing features with lots of nulls: {len(features_list)}')\n\n\nmy_dataset = data_dict\n\n### Extract features and labels from dataset for local testing\ndata = featureFormat(my_dataset, features_list, sort_keys = True)\nlabels, features = targetFeatureSplit(data)\n",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "No of columns to remove: 6\n['deferral_payments', 'loan_advances', 'restricted_stock_deferred', 'deferred_income', 'long_term_incentive', 'director_fees']\nNo of Features: 20\n['poi', 'salary', 'total_payments', 'bonus', 'total_stock_value', 'expenses', 'exercised_stock_options', 'other', 'restricted_stock', 'shared_receipt_with_poi', 'to_messages', 'from_messages', 'from_poi_to_this_person', 'from_this_person_to_poi']\nNo of Features after removing features with lots of nulls: 14\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\n### Task 4: Try a varity of classifiers\n### Please name your classifier clf for easy export below.\n### Note that if you want to do PCA or other multi-stage operations,\n### you'll need to use Pipelines. For more info:\n### http://scikit-learn.org/stable/modules/pipeline.html\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score\n\nfeatures_train, features_test, labels_train, labels_test = \\\n    train_test_split(features, labels, test_size=0.3, random_state=42)\n\nclf = DecisionTreeClassifier(min_samples_split=7)\nclf.fit(features_train, labels_train)\npred = clf.predict(features_test)\nacc_score = accuracy_score(labels_test, pred)\ndt_precision_score = precision_score(labels_test, pred)\ndt_recall_score = recall_score(labels_test, pred)\ndt_confusion_matrix = confusion_matrix(labels_test, pred)\nprint(f'Accuracy score with DT is: {acc_score}')\nprint(f'Precision score with DT is: {dt_precision_score}')\nprint(f'Recall score with DT is: {dt_recall_score}')\nprint(dt_confusion_matrix)\n",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Accuracy score with DT is: 0.8409090909090909\nPrecision score with DT is: 0.25\nRecall score with DT is: 0.2\n[[36  3]\n [ 4  1]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\n# Provided to give you a starting point. Try a variety of classifiers.\n#from sklearn.naive_bayes import GaussianNB\n#clf = GaussianNB()\n\n### Task 5: Tune your classifier to achieve better than .3 precision and recall\n### using our testing script. Check the tester.py script in the final project\n### folder for details on the evaluation method, especially the test_classifier\n### function. Because of the small size of the dataset, the script uses\n### stratified shuffle split cross validation. For more info:\n### http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedShuffleSplit.html\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import GridSearchCV\nfrom time import time\n\nstart = time()\nestimators = [('reduce_dim', PCA()), ('clf', SVC())]\npipe = Pipeline(estimators)\n\nparam_grid = dict(reduce_dim__n_components=[8, 10], clf__C=[0.1, 10, 100])\n#param_grid = dict(reduce_dim__n_components=[5, 10], clf__C=[0.1, 10, 100])\nclf = GridSearchCV(pipe, param_grid=param_grid, n_jobs=-1, scoring='f1', cv=5, return_train_score=True)\nclf.fit(features_train, labels_train)\nprint(f'Grid Search score: {clf.score(features_test, labels_test)}')\nprint(sorted(clf.cv_results_.keys()))\nprint(f'Best params: {clf.best_params_}')\n#print(clf.cv_results_)\n\nprint(f'Finished in: {time()-start:.2f} seconds')\n#print(f'Grid Search precision: {precision_score(features_test, labels_test)}')\n#print(f'Grid Search recall: {recall_score(features_test, labels_test)}')\n\n# Example starting point. Try investigating other evaluation techniques!\n#from sklearn.model_selection import train_test_split\n#features_train, features_test, labels_train, labels_test = \\\n#    train_test_split(features, labels, test_size=0.3, random_state=42)\n\n### Task 6: Dump your classifier, dataset, and features_list so anyone can\n### check your results. You do not need to change anything below, but make sure\n### that the version of poi_id.py that you submit can be run on its own and\n### generates the necessary .pkl files for validating your results.\n\ndump_classifier_and_data(clf, my_dataset, features_list)",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n  \"avoid this warning.\", FutureWarning)\n/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n  'precision', 'predicted', average, warn_for)\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "Grid Search score: 0.0\n['mean_fit_time', 'mean_score_time', 'mean_test_score', 'mean_train_score', 'param_clf__C', 'param_reduce_dim__n_components', 'params', 'rank_test_score', 'split0_test_score', 'split0_train_score', 'split1_test_score', 'split1_train_score', 'split2_test_score', 'split2_train_score', 'split3_test_score', 'split3_train_score', 'split4_test_score', 'split4_train_score', 'std_fit_time', 'std_score_time', 'std_test_score', 'std_train_score']\nBest params: {'clf__C': 0.1, 'reduce_dim__n_components': 8}\nFinished in: 40.97 seconds\n",
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-28c9a847406f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m### generates the necessary .pkl files for validating your results.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mdump_classifier_and_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/library/ud120-projects/final_project/tester.py\u001b[0m in \u001b[0;36mdump_classifier_and_data\u001b[0;34m(clf, dataset, feature_list)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdump_classifier_and_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCLF_PICKLE_FILENAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mclf_outfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf_outfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATASET_PICKLE_FILENAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdataset_outfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_outfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}